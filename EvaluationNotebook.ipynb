{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for stencil validation and timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jan, Nina Horat & Laura Endres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name Lists\n",
    "stencil_name_list = [\n",
    "        \"test\",\n",
    "        \"laplacian1d\", \n",
    "        \"laplacian2d\",\n",
    "        \"laplacian3d\",\n",
    "        \"FMA\",\n",
    "       \"lapoflap1d\",\n",
    "        \"lapoflap2d\",\n",
    "        \"lapoflap3d\",\n",
    "        \"test_gt4py\",\n",
    "    ]\n",
    "\n",
    "backend_list = [\"numpy\", \n",
    "                \"numba_vector_function\", \n",
    "                \"numba_vector_decorator\", \n",
    "                \"numba_loop\", \n",
    "                \"numba_stencil\", \n",
    "                \"gt4py\"]\n",
    "\n",
    "gt4py_backend_list = [\n",
    "        \"numpy\", \n",
    "        \"gtx86\", \n",
    "        \"gtmc\", \n",
    "        \"gtcuda\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "### Create testfields\n",
    "We create one testfield per stencil_name (option --create_field = True). After creation the fields are saved in the folder testfields and can be accessed by the option --field_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in stencil_name_list:\n",
    "    \n",
    "    bashCommand=f\"python3 stencil_main_validation.py --nx 32 --ny 32 --nz 32 --stencil_name {x} --backend numpy --create_field True --field_name {x}\"\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    \n",
    "    print(output.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in stencil_name_list:\n",
    "    print(x,':')\n",
    "    for y in backend_list:\n",
    "        \n",
    "        if y=='gt4py':\n",
    "            if x=='test':\n",
    "                print('There is no test stencil in gt4py.')\n",
    "            else:\n",
    "                for z in gt4py_backend_list:\n",
    "                    bashCommand=f\"python3 stencil_main_validation.py --nx 32 --ny 32 --nz 32 --stencil_name {x} --backend {y} --gt4py_backend {z} --create_field False --field_name {x}\"\n",
    "                    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "                    output, error = process.communicate()\n",
    "                    print(output.decode(\"utf-8\"),' for ', z)\n",
    "                \n",
    "        else:\n",
    "            bashCommand=f\"python3 stencil_main_validation.py --nx 32 --ny 32 --nz 32 --stencil_name {x} --backend {y} --create_field False --field_name {x}\"\n",
    "            process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "            output, error = process.communicate()\n",
    "            print(output.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing\n",
    "### Execute Stencil computation for evaluation\n",
    "In this section the different stencils for the different domain sizes are calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes some time...\n",
    "#Parameter \n",
    "field_size_list = [16,32]\n",
    "df_name = \"val_L\" #Name of evaluation dataframe\n",
    "num_iter = 20\n",
    "\n",
    "#Stencil computation\n",
    "for size in field_size_list:\n",
    "    print(size,':')\n",
    "    for x in stencil_name_list:\n",
    "        print('    ',x,':')\n",
    "        for y in backend_list:\n",
    "            bashCommand=f\"python3 stencil_main_performance.py --nx {size} --ny {size} --nz {size} --stencil_name {x} --backend {y} --num_iter {num_iter} --df_name {df_name}\"\n",
    "            process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "            print(y,' calculated.')\n",
    "            #output, error = process.communicate()\n",
    "            #print(output.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read out the dataframe and plot results\n",
    "The program saves the evaluation data into a pandas dataframe (Name is defined with the option --df_name). Subsequently the df can be accessed for further processing within a jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"val_L\" #Name of df to evaluate\n",
    "df = pd.read_pickle(\"eval/{}_result.pkl\".format(df_name))\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"val_L\" #Name of df to evaluate\n",
    "df = pd.read_pickle(\"eval/{}_result.pkl\".format(df_name))\n",
    "\n",
    "for size in field_size_list:\n",
    "        df_plot = df.loc[df[\"nx\"]==size]\n",
    "        plt.figure(figsize=(10,5))\n",
    "        chart=sns.barplot(x=\"stencil_name\", y=\"run_avg\", hue=\"backend\",data=df_plot, ci=False)\n",
    "        chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
    "        chart.legend(loc='upper left')\n",
    "        chart.set_title('Stencil computation for nx,ny,nz={}'.format(size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_name = \"val_1\" #Name of df to evaluate\n",
    "df = pd.read_pickle(\"eval/{}_result.pkl\".format(df_name))\n",
    "df.tail(10)\n",
    "\n",
    "df16=df.loc[df[\"nx\"]==16]\n",
    "plt.figure(figsize=(10,5))\n",
    "chart=sns.barplot(x=\"stencil_name\", y=\"run_avg\", hue=\"backend\",data=df16, ci=False)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
    "chart.legend(loc='upper left')\n",
    "\n",
    "\n",
    "df32=df.loc[df[\"nx\"]==32]\n",
    "plt.figure(figsize=(10,5))\n",
    "chart=sns.barplot(x=\"stencil_name\", y=\"run_avg\", hue=\"backend\",data=df32, ci=False)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
    "chart.legend(loc='upper left')\n",
    "\n",
    "df64=df.loc[df[\"nx\"]==64]\n",
    "plt.figure(figsize=(10,5))\n",
    "chart=sns.barplot(x=\"stencil_name\", y=\"run_avg\", hue=\"backend\",data=df64, ci=False)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
    "chart.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############first try to add error bars. \n",
    "#the location of the bars is still wrong since the rows get ordered differently when .groupby is applied. \n",
    "#also I had to add data points for gt4py and numba_stencil where the function do not yet work.\n",
    "#but this would be an option to get the error bars on top of everything.\n",
    "#https://stackoverflow.com/questions/62820959/use-precalculated-error-bars-with-seaborn-and-barplot\n",
    "#https://matplotlib.org/gallery/lines_bars_and_markers/errorbar_limits_simple.html#sphx-glr-gallery-lines-bars-and-markers-errorbar-limits-simple-py\n",
    "\n",
    "df_name = \"val_1\" #Name of df to evaluate\n",
    "df = pd.read_pickle(\"eval/{}_result.pkl\".format(df_name))\n",
    "df.tail(10)\n",
    "\n",
    "df16=df.loc[df[\"nx\"]==16]\n",
    "plt.figure(figsize=(10,5))\n",
    "chart =sns.barplot(x=\"stencil_name\", y=\"run_avg\", hue=\"backend\",data=df16, ci=False)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
    "chart.legend(loc='upper left')\n",
    "\n",
    "conc2=[0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,5,5,5,5,5,5,6,6,6,6,6,6,7,7,7,7,7,7]\n",
    "width = .25\n",
    "add = [-2.5*width, -1.5*width, -0.5*width, 0.5*width , 1.5*width, 2.5*width, -2.5*width, -1.5*width, -0.5*width, 0.5*width , 1.5*width, 2.5*width,\n",
    "       -2.5*width, -1.5*width, -0.5*width, 0.5*width , 1.5*width, 2.5*width,-2.5*width, -1.5*width, -0.5*width, 0.5*width , 1.5*width, 2.5*width,\n",
    "       -2.5*width, -1.5*width, -0.5*width, 0.5*width , 1.5*width, 2.5*width,-2.5*width, -1.5*width, -0.5*width, 0.5*width , 1.5*width, 2.5*width,\n",
    "       -2.5*width, -1.5*width, -0.5*width, 0.5*width , 1.5*width, 2.5*width,-2.5*width, -1.5*width, -0.5*width, 0.5*width , 1.5*width, 2.5*width,\n",
    "      ]\n",
    "x = np.array(conc2)+np.array(add)\n",
    "#print(x)\n",
    "\n",
    "df16_stdev=df16.groupby(['stencil_name','backend']).mean()\n",
    "df16_stdev=df16_stdev.append(df16_stdev[-4:-1])\n",
    "#print(df16_stdev)\n",
    "print(df16_stdev.shape)\n",
    "plt.errorbar(x = x, y = df16_stdev['run_avg'],\n",
    "            yerr = df16_stdev['run_stdev'],\n",
    "             fmt='none', c= 'black', capsize = 2\n",
    "            )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear df on disk\n",
    "df_name = \"test\"\n",
    "os.remove(\"eval/{}_result.pkl\".format(df_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Runtime\n",
    "We suspect that different number of iterations will lead to different runtime developments.\n",
    "This can be tested with the option --save_runtime. The df runtimedevelopment can afterwards be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtime = pd.read_pickle(\"eval/runtimedevelopment.pkl\")\n",
    "df_runtime.columns = ['runtime']\n",
    "df_runtime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtime.plot()\n",
    "#numba_loop 32x32x32 stencil: lapoflap3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtime.plot()\n",
    "#numba_loop 64x64x64 stencil: lapoflap3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtime.plot()\n",
    "#numba_vector_function 64x64x64 stencil: lapoflap3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
